{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 임포트\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "#이미지 생성용\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter\n",
    "\n",
    "# 콜백 함수\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#시간 구하기용\n",
    "from datetime import datetime\n",
    "\n",
    "#디렉토리 생성용\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelDesign(size_x, size_y, depth, label_num, regularizer_value):     \n",
    "    #초기화\n",
    "    model = Sequential() \n",
    "    \n",
    "    # CNN 레이어\n",
    "    # 레이어1(Input)\n",
    "    model.add(Conv2D(filters=96,\n",
    "                     input_shape=(size_x,size_y,depth),\n",
    "                     kernel_size=(11,11),\n",
    "                     strides=(4,4),\n",
    "                     padding='valid',\n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    # Activation\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling \n",
    "    model.add(MaxPooling2D((2,2), strides=(1,1), padding='valid'))\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어2\n",
    "    model.add(Conv2D(filters=256, kernel_size=(11,11), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D((2,2), strides=(1,1), padding='valid'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어3\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어4\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어5\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Dense 레이어\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 레이어1(Input2)\n",
    "    model.add(Dense(4096, input_shape=(size_x*size_y*depth,), \n",
    "                    kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.8))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 레이어2\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.8))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 레이어3\n",
    "    model.add(Dense(1000, kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.8))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 출력 레이어\n",
    "    model.add(Dense(label_num))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #모델 확인\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 29, 29, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 19, 19, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 19, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                16016     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 64,795,928\n",
      "Trainable params: 64,774,792\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 설정값들\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_DEPTH = 3\n",
    "LABEL_NUM = 16\n",
    "REGULIZER = 0.0001\n",
    "\n",
    "#GetCNN Model\n",
    "model = ModelDesign(IMAGE_SIZE, IMAGE_SIZE, IMAGE_DEPTH, LABEL_NUM, REGULIZER)\n",
    "\n",
    "#Compling CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val값에 따라 훈련 조기종료 설정\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "\n",
    "# Class Weights 계산\n",
    "# 가장 많은 클레스의 수 / 각 클레스의 수\n",
    "# 클레스 = 각 라벨에 해당하는 데이터 수\n",
    "'''\n",
    "counter = Counter(training_set.classes)\n",
    "max_val = float(max(counter.values()))\n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\n",
    "'''\n",
    "#오늘 날짜_시간\n",
    "NOW = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "#텐서보드 로그\n",
    "tensorboard = TensorBoard(log_dir=\"./Logs/AlexNet/\" + NOW)\n",
    "\n",
    "#디렉토리 생성\n",
    "def MakeDirectory(dir_path):\n",
    "    try:\n",
    "        if not(os.path.isdir(dir_path)):\n",
    "            os.makedirs(os.path.join(dir_path))\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle  1\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 186s 95ms/step - loss: 5.1268 - acc: 0.2007 - val_loss: 5.3953 - val_acc: 0.2431\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 5.6883 - acc: 0.2391 - val_loss: 7.0804 - val_acc: 0.2325\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 5.9573 - acc: 0.2495 - val_loss: 6.0716 - val_acc: 0.2532\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 709s 330ms/step - loss: 6.1604 - acc: 0.2558 - val_loss: 6.5232 - val_acc: 0.2451\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 193s 90ms/step - loss: 6.0247 - acc: 0.2606 - val_loss: 5.7469 - val_acc: 0.2454\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 5.4484 - acc: 0.2618 - val_loss: 4.9419 - val_acc: 0.2443\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 4.6563 - acc: 0.2622 - val_loss: 4.5477 - val_acc: 0.2458\n",
      "Epoch 5/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 4.4662 - acc: 0.2621 - val_loss: 4.1883 - val_acc: 0.2451\n",
      "Epoch 6/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 4.1868 - acc: 0.2625 - val_loss: 4.0302 - val_acc: 0.2420\n",
      "Epoch 7/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.7663 - acc: 0.2622 - val_loss: 3.8049 - val_acc: 0.2443\n",
      "Epoch 8/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.7321 - acc: 0.2622 - val_loss: 3.8465 - val_acc: 0.2452\n",
      "Epoch 9/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.6355 - acc: 0.2620 - val_loss: 3.6104 - val_acc: 0.2456\n",
      "Epoch 10/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.5793 - acc: 0.2624 - val_loss: 3.4789 - val_acc: 0.2462\n",
      "Epoch 11/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.6716 - acc: 0.2623 - val_loss: 3.7561 - val_acc: 0.2441\n",
      "Epoch 12/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.6741 - acc: 0.2622 - val_loss: 3.7429 - val_acc: 0.2457\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 688s 353ms/step - loss: 3.5610 - acc: 0.2676 - val_loss: 3.6978 - val_acc: 0.2317\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.6439 - acc: 0.2676 - val_loss: 4.1255 - val_acc: 0.2315\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.7190 - acc: 0.2676 - val_loss: 3.8261 - val_acc: 0.2320\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 691s 345ms/step - loss: 3.9161 - acc: 0.2543 - val_loss: 3.9387 - val_acc: 0.2864\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.9272 - acc: 0.2543 - val_loss: 3.8503 - val_acc: 0.2858\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.7533 - acc: 0.2543 - val_loss: 3.7314 - val_acc: 0.2862\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.7590 - acc: 0.2543 - val_loss: 4.3295 - val_acc: 0.2860\n",
      "Epoch 5/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.8679 - acc: 0.2544 - val_loss: 3.7066 - val_acc: 0.28726 \n",
      "Epoch 6/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.8191 - acc: 0.2544 - val_loss: 3.7888 - val_acc: 0.2853\n",
      "Epoch 7/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.8178 - acc: 0.2545 - val_loss: 3.7047 - val_acc: 0.2858\n",
      "Epoch 8/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.6285 - acc: 0.2542 - val_loss: 3.5985 - val_acc: 0.2865\n",
      "Epoch 9/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.6296 - acc: 0.2543 - val_loss: 12.3092 - val_acc: 0.2862\n",
      "Epoch 10/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.6189 - acc: 0.2546 - val_loss: 3.9720 - val_acc: 0.2860\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 517s 251ms/step - loss: 3.5639 - acc: 0.2553 - val_loss: 3.6030 - val_acc: 0.2862\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5307 - acc: 0.2552 - val_loss: 3.7520 - val_acc: 0.2857\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5331 - acc: 0.2552 - val_loss: 3.4388 - val_acc: 0.2857\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5204 - acc: 0.2552 - val_loss: 3.3732 - val_acc: 0.2864\n",
      "Epoch 5/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5608 - acc: 0.2553 - val_loss: 11.9217 - val_acc: 0.2852\n",
      "Epoch 6/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5132 - acc: 0.2554 - val_loss: 12.5604 - val_acc: 0.2863\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.5631 - acc: 0.2598 - val_loss: 7.6648 - val_acc: 0.2625\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.4958 - acc: 0.2600 - val_loss: 8.2331 - val_acc: 0.2624\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.6334 - acc: 0.2601 - val_loss: 3.8769 - val_acc: 0.2622\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.7068 - acc: 0.2597 - val_loss: 4.8154 - val_acc: 0.2627\n",
      "Epoch 5/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.5070 - acc: 0.2601 - val_loss: 3.5057 - val_acc: 0.2616\n",
      "Epoch 6/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.5443 - acc: 0.2596 - val_loss: 3.8180 - val_acc: 0.2621\n",
      "Epoch 7/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.6057 - acc: 0.2599 - val_loss: 3.5504 - val_acc: 0.2633\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  2\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.5478 - acc: 0.2619 - val_loss: 3.4759 - val_acc: 0.2532\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.5463 - acc: 0.2619 - val_loss: 4.0355 - val_acc: 0.2530\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.5502 - acc: 0.2618 - val_loss: 4.5612 - val_acc: 0.2539\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.6454 - acc: 0.2623 - val_loss: 3.5630 - val_acc: 0.2454\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.5911 - acc: 0.2622 - val_loss: 10.6728 - val_acc: 0.2451\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.8092 - acc: 0.2624 - val_loss: 3.8163 - val_acc: 0.2451\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 178s 91ms/step - loss: 3.7123 - acc: 0.2676 - val_loss: 3.6669 - val_acc: 0.2316\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 178s 91ms/step - loss: 3.5890 - acc: 0.2676 - val_loss: 3.5965 - val_acc: 0.2318\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 178s 91ms/step - loss: 3.5151 - acc: 0.2676 - val_loss: 3.4508 - val_acc: 0.2314\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 [==============================] - 178s 91ms/step - loss: 3.4427 - acc: 0.2676 - val_loss: 3.5371 - val_acc: 0.2317\n",
      "Epoch 5/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.5158 - acc: 0.2676 - val_loss: 3.5848 - val_acc: 0.2320\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.6203 - acc: 0.2544 - val_loss: 3.6064 - val_acc: 0.2862\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.6545 - acc: 0.2543 - val_loss: 3.5771 - val_acc: 0.2860\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.6642 - acc: 0.2544 - val_loss: 4.2873 - val_acc: 0.2865\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.5166 - acc: 0.2544 - val_loss: 3.3888 - val_acc: 0.2863\n",
      "Epoch 5/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.3777 - acc: 0.2544 - val_loss: 3.4535 - val_acc: 0.2854\n",
      "Epoch 6/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.4948 - acc: 0.2544 - val_loss: 11.3799 - val_acc: 0.2867\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5409 - acc: 0.2553 - val_loss: 5.2194 - val_acc: 0.2858\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5851 - acc: 0.2555 - val_loss: 3.3996 - val_acc: 0.2860\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5512 - acc: 0.2552 - val_loss: 3.3425 - val_acc: 0.2859\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5267 - acc: 0.2555 - val_loss: 3.4837 - val_acc: 0.2853\n",
      "Epoch 5/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.5765 - acc: 0.2555 - val_loss: 3.4938 - val_acc: 0.2860\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.5651 - acc: 0.2599 - val_loss: 3.7243 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.6655 - acc: 0.2597 - val_loss: 3.6531 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.6426 - acc: 0.2601 - val_loss: 3.6689 - val_acc: 0.2629\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.5988 - acc: 0.2596 - val_loss: 4.4873 - val_acc: 0.2617\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  3\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.5522 - acc: 0.2619 - val_loss: 3.4170 - val_acc: 0.2533\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.5304 - acc: 0.2620 - val_loss: 3.4217 - val_acc: 0.2532\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.4731 - acc: 0.2618 - val_loss: 3.5813 - val_acc: 0.2534\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.5068 - acc: 0.2623 - val_loss: 3.5122 - val_acc: 0.2451\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.5298 - acc: 0.2623 - val_loss: 3.4503 - val_acc: 0.2455\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.4955 - acc: 0.2622 - val_loss: 3.4806 - val_acc: 0.2450\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.4921 - acc: 0.2622 - val_loss: 3.4201 - val_acc: 0.2451\n",
      "Epoch 5/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.4722 - acc: 0.2621 - val_loss: 3.4731 - val_acc: 0.2448\n",
      "Epoch 6/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.4538 - acc: 0.2625 - val_loss: 3.3722 - val_acc: 0.2459\n",
      "Epoch 7/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.4757 - acc: 0.2620 - val_loss: 3.4339 - val_acc: 0.2451\n",
      "Epoch 8/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.4474 - acc: 0.2623 - val_loss: 3.3855 - val_acc: 0.2453\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.5224 - acc: 0.2676 - val_loss: 3.5949 - val_acc: 0.2317\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.4957 - acc: 0.2676 - val_loss: 3.5777 - val_acc: 0.2315\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.4307 - acc: 0.2676 - val_loss: 3.5126 - val_acc: 0.2317\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.4463 - acc: 0.2676 - val_loss: 3.3321 - val_acc: 0.2318\n",
      "Epoch 5/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.1914 - acc: 0.2676 - val_loss: 3.3523 - val_acc: 0.2315\n",
      "Epoch 6/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.2080 - acc: 0.2676 - val_loss: 4.5848 - val_acc: 0.2316\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.2304 - acc: 0.2544 - val_loss: 3.1286 - val_acc: 0.2857\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.2295 - acc: 0.2545 - val_loss: 3.1297 - val_acc: 0.2870\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.2842 - acc: 0.2544 - val_loss: 3.8724 - val_acc: 0.2858\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.3233 - acc: 0.2553 - val_loss: 3.2279 - val_acc: 0.2858\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 185s 90ms/step - loss: 3.2361 - acc: 0.2552 - val_loss: 3.1567 - val_acc: 0.2857\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 185s 90ms/step - loss: 3.3401 - acc: 0.2553 - val_loss: 3.2948 - val_acc: 0.2863\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 185s 90ms/step - loss: 3.3871 - acc: 0.2551 - val_loss: 3.2151 - val_acc: 0.2862\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2955 - acc: 0.2598 - val_loss: 3.2186 - val_acc: 0.2622\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.4159 - acc: 0.2599 - val_loss: 3.6462 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.4488 - acc: 0.2600 - val_loss: 3.7104 - val_acc: 0.2629\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  4\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.3623 - acc: 0.2619 - val_loss: 3.3692 - val_acc: 0.2533\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.2815 - acc: 0.2620 - val_loss: 3.4874 - val_acc: 0.2532\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.3387 - acc: 0.2619 - val_loss: 3.3124 - val_acc: 0.2536\n",
      "Epoch 4/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.3311 - acc: 0.2619 - val_loss: 3.1697 - val_acc: 0.2530\n",
      "Epoch 5/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.3152 - acc: 0.2618 - val_loss: 3.3367 - val_acc: 0.2536\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.3025 - acc: 0.2620 - val_loss: 4.3129 - val_acc: 0.2530\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.2910 - acc: 0.2623 - val_loss: 3.3255 - val_acc: 0.2452\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.3000 - acc: 0.2622 - val_loss: 3.2327 - val_acc: 0.2454\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.2864 - acc: 0.2622 - val_loss: 3.2597 - val_acc: 0.2452\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.2672 - acc: 0.2625 - val_loss: 3.4239 - val_acc: 0.2442\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 178s 91ms/step - loss: 3.2179 - acc: 0.2676 - val_loss: 3.2684 - val_acc: 0.2317\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.2308 - acc: 0.2676 - val_loss: 3.1328 - val_acc: 0.2317\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 178s 91ms/step - loss: 3.1466 - acc: 0.2676 - val_loss: 3.1747 - val_acc: 0.2314\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.1822 - acc: 0.2676 - val_loss: 3.3735 - val_acc: 0.2317\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.2554 - acc: 0.2544 - val_loss: 3.1802 - val_acc: 0.2862\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.2441 - acc: 0.2543 - val_loss: 3.4558 - val_acc: 0.2861\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.3302 - acc: 0.2544 - val_loss: 3.3296 - val_acc: 0.2858\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.3521 - acc: 0.2553 - val_loss: 3.2691 - val_acc: 0.2860\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.2125 - acc: 0.2553 - val_loss: 5.4024 - val_acc: 0.2858\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.2144 - acc: 0.2552 - val_loss: 3.1578 - val_acc: 0.2855\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.1923 - acc: 0.2554 - val_loss: 3.1912 - val_acc: 0.2862\n",
      "Epoch 5/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.2189 - acc: 0.2555 - val_loss: 8.3056 - val_acc: 0.2867\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.3483 - acc: 0.2598 - val_loss: 3.5980 - val_acc: 0.2622\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2474 - acc: 0.2598 - val_loss: 6.5140 - val_acc: 0.2621\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2135 - acc: 0.2597 - val_loss: 3.3421 - val_acc: 0.2627\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.3164 - acc: 0.2599 - val_loss: 9.3601 - val_acc: 0.2625\n",
      "Epoch 5/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2737 - acc: 0.2599 - val_loss: 4.9228 - val_acc: 0.2624\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  5\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.3210 - acc: 0.2619 - val_loss: 3.3653 - val_acc: 0.2532ss: 3.3214 \n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1898 - acc: 0.2618 - val_loss: 5.9208 - val_acc: 0.2534\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1649 - acc: 0.2618 - val_loss: 4.1277 - val_acc: 0.2533\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.0786 - acc: 0.2622 - val_loss: 3.0189 - val_acc: 0.2452\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.0399 - acc: 0.2623 - val_loss: 3.0324 - val_acc: 0.2451\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.0945 - acc: 0.2623 - val_loss: 3.2534 - val_acc: 0.2448\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0297 - acc: 0.2676 - val_loss: 3.0962 - val_acc: 0.2317\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 2.9929 - acc: 0.2676 - val_loss: 3.1305 - val_acc: 0.2316\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0443 - acc: 0.2676 - val_loss: 3.1057 - val_acc: 0.2319\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.1353 - acc: 0.2544 - val_loss: 3.2634 - val_acc: 0.2863\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.1870 - acc: 0.2544 - val_loss: 3.1084 - val_acc: 0.2861\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.1510 - acc: 0.2543 - val_loss: 3.1482 - val_acc: 0.2856\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.0887 - acc: 0.2543 - val_loss: 3.0529 - val_acc: 0.2865\n",
      "Epoch 5/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.2318 - acc: 0.2544 - val_loss: 3.1306 - val_acc: 0.2868\n",
      "Epoch 6/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.2405 - acc: 0.2545 - val_loss: 3.1393 - val_acc: 0.2856\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.1681 - acc: 0.2553 - val_loss: 3.1917 - val_acc: 0.2860\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.2225 - acc: 0.2552 - val_loss: 3.1176 - val_acc: 0.2859\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.1768 - acc: 0.2552 - val_loss: 3.0642 - val_acc: 0.2857\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.0818 - acc: 0.2554 - val_loss: 4.3166 - val_acc: 0.2867\n",
      "Epoch 5/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.0148 - acc: 0.2553 - val_loss: 3.0049 - val_acc: 0.2855\n",
      "Epoch 6/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.0890 - acc: 0.2549 - val_loss: 3.0136 - val_acc: 0.2852\n",
      "Epoch 7/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.1264 - acc: 0.2557 - val_loss: 3.0952 - val_acc: 0.2861\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2225 - acc: 0.2598 - val_loss: 3.9548 - val_acc: 0.2624\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2773 - acc: 0.2598 - val_loss: 3.2678 - val_acc: 0.2621\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2434 - acc: 0.2600 - val_loss: 3.1746 - val_acc: 0.2615\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2253 - acc: 0.2598 - val_loss: 3.1697 - val_acc: 0.2635\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.1671 - acc: 0.2597 - val_loss: 3.4441 - val_acc: 0.2617\n",
      "Epoch 6/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2175 - acc: 0.2598 - val_loss: 4.6246 - val_acc: 0.2533\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  6\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.2337 - acc: 0.2619 - val_loss: 3.1251 - val_acc: 0.2533\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1705 - acc: 0.2620 - val_loss: 3.4707 - val_acc: 0.2536\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1076 - acc: 0.2619 - val_loss: 3.1527 - val_acc: 0.2530\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.0847 - acc: 0.2623 - val_loss: 3.1709 - val_acc: 0.2453\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.1251 - acc: 0.2621 - val_loss: 3.0781 - val_acc: 0.2447\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.1006 - acc: 0.2622 - val_loss: 3.1579 - val_acc: 0.2456\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 192s 89ms/step - loss: 3.1576 - acc: 0.2622 - val_loss: 6.5721 - val_acc: 0.2446\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.1340 - acc: 0.2676 - val_loss: 4.5647 - val_acc: 0.2316\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0964 - acc: 0.2676 - val_loss: 3.1365 - val_acc: 0.2319\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0506 - acc: 0.2676 - val_loss: 12.6948 - val_acc: 0.2314\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0407 - acc: 0.2676 - val_loss: 3.2159 - val_acc: 0.2315\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.1218 - acc: 0.2544 - val_loss: 3.1601 - val_acc: 0.2862\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.2344 - acc: 0.2544 - val_loss: 3.2303 - val_acc: 0.2861\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.1985 - acc: 0.2544 - val_loss: 3.0641 - val_acc: 0.2862\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.1672 - acc: 0.2545 - val_loss: 3.1411 - val_acc: 0.2865\n",
      "Epoch 5/20\n",
      "2004/2004 [==============================] - 181s 91ms/step - loss: 3.0776 - acc: 0.2541 - val_loss: 3.0141 - val_acc: 0.2859\n",
      "Epoch 6/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.1352 - acc: 0.2544 - val_loss: 3.2032 - val_acc: 0.2867\n",
      "Epoch 7/20\n",
      "2004/2004 [==============================] - 182s 91ms/step - loss: 3.1794 - acc: 0.2545 - val_loss: 7.1195 - val_acc: 0.2862\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.0885 - acc: 0.2553 - val_loss: 3.0334 - val_acc: 0.2859\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.0809 - acc: 0.2554 - val_loss: 3.3456 - val_acc: 0.2863\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.1726 - acc: 0.2551 - val_loss: 3.2065 - val_acc: 0.2856\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2871 - acc: 0.2598 - val_loss: 4.2219 - val_acc: 0.2624\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.3619 - acc: 0.2600 - val_loss: 4.4401 - val_acc: 0.2625\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.2283 - acc: 0.2598 - val_loss: 5.8872 - val_acc: 0.2621\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  7\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1533 - acc: 0.2618 - val_loss: 3.1233 - val_acc: 0.2533\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.0930 - acc: 0.2619 - val_loss: 3.1682 - val_acc: 0.2532\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1164 - acc: 0.2620 - val_loss: 3.1021 - val_acc: 0.2532\n",
      "Epoch 4/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1285 - acc: 0.2621 - val_loss: 3.1872 - val_acc: 0.2530\n",
      "Epoch 5/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.1384 - acc: 0.2617 - val_loss: 3.0338 - val_acc: 0.2535\n",
      "Epoch 6/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.0358 - acc: 0.2621 - val_loss: 3.5723 - val_acc: 0.2532\n",
      "Epoch 7/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.0846 - acc: 0.2619 - val_loss: 3.1601 - val_acc: 0.2539\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0546 - acc: 0.2622 - val_loss: 3.2834 - val_acc: 0.2450\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0563 - acc: 0.2625 - val_loss: 3.0768 - val_acc: 0.2457\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0529 - acc: 0.2623 - val_loss: 3.0163 - val_acc: 0.2455\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.1201 - acc: 0.2622 - val_loss: 3.0317 - val_acc: 0.2445\n",
      "Epoch 5/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0640 - acc: 0.2623 - val_loss: 4.1465 - val_acc: 0.2453\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0771 - acc: 0.2676 - val_loss: 3.1845 - val_acc: 0.2317\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0162 - acc: 0.2676 - val_loss: 3.1953 - val_acc: 0.2316\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0560 - acc: 0.2676 - val_loss: 12.9896 - val_acc: 0.2315\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 181s 90ms/step - loss: 3.0975 - acc: 0.2544 - val_loss: 3.0723 - val_acc: 0.2859\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 181s 90ms/step - loss: 3.1242 - acc: 0.2542 - val_loss: 3.1528 - val_acc: 0.2866\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 181s 90ms/step - loss: 3.1620 - acc: 0.2544 - val_loss: 3.0204 - val_acc: 0.2863\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 181s 90ms/step - loss: 3.0684 - acc: 0.2542 - val_loss: 3.0726 - val_acc: 0.2867\n",
      "Epoch 5/20\n",
      "2004/2004 [==============================] - 181s 90ms/step - loss: 3.1250 - acc: 0.2546 - val_loss: 3.1731 - val_acc: 0.2857\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 185s 90ms/step - loss: 3.1486 - acc: 0.2553 - val_loss: 3.0468 - val_acc: 0.2861\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 185s 90ms/step - loss: 3.1005 - acc: 0.2556 - val_loss: 4.8198 - val_acc: 0.2859\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2062/2062 [==============================] - 185s 90ms/step - loss: 3.1137 - acc: 0.2555 - val_loss: 6.8289 - val_acc: 0.2863\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 190s 89ms/step - loss: 3.1163 - acc: 0.2598 - val_loss: 3.8629 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 190s 89ms/step - loss: 3.1077 - acc: 0.2598 - val_loss: 3.0857 - val_acc: 0.2622\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 190s 89ms/step - loss: 3.0677 - acc: 0.2601 - val_loss: 5.5637 - val_acc: 0.2622\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 190s 89ms/step - loss: 3.1187 - acc: 0.2596 - val_loss: 12.2000 - val_acc: 0.2628\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  8\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.0135 - acc: 0.2619 - val_loss: 3.1929 - val_acc: 0.2533\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 2.9746 - acc: 0.2619 - val_loss: 3.1290 - val_acc: 0.2531\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.0253 - acc: 0.2619 - val_loss: 3.7553 - val_acc: 0.2533\n",
      "Epoch 4/20\n",
      "1955/1955 [==============================] - 178s 91ms/step - loss: 3.0843 - acc: 0.2618 - val_loss: 3.1521 - val_acc: 0.2536\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0088 - acc: 0.2623 - val_loss: 4.3763 - val_acc: 0.2452\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0209 - acc: 0.2621 - val_loss: 10.7390 - val_acc: 0.2453\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0408 - acc: 0.2621 - val_loss: 2.9513 - val_acc: 0.2455\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 3.0429 - acc: 0.2624 - val_loss: 4.7626 - val_acc: 0.2452\n",
      "Epoch 5/20\n",
      "2150/2150 [==============================] - 191s 89ms/step - loss: 2.9763 - acc: 0.2622 - val_loss: 10.9578 - val_acc: 0.2446\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 2.9852 - acc: 0.2676 - val_loss: 12.9381 - val_acc: 0.2316\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 2.9900 - acc: 0.2676 - val_loss: 3.0989 - val_acc: 0.2317\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 177s 91ms/step - loss: 3.0404 - acc: 0.2676 - val_loss: 5.0485 - val_acc: 0.2317\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 179s 92ms/step - loss: 3.1007 - acc: 0.2676 - val_loss: 13.0395 - val_acc: 0.2316\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 183s 91ms/step - loss: 3.1393 - acc: 0.2544 - val_loss: 7.1752 - val_acc: 0.2859\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 185s 92ms/step - loss: 3.1095 - acc: 0.2542 - val_loss: 4.8278 - val_acc: 0.2868\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 183s 91ms/step - loss: 3.0709 - acc: 0.2544 - val_loss: 3.2044 - val_acc: 0.2850\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 183s 91ms/step - loss: 3.0738 - acc: 0.2545 - val_loss: 8.0604 - val_acc: 0.2861: 1s - loss: 3.0743 - a - ETA: 0s - loss: 3.0737 - acc: 0.25\n",
      "Epoch 5/20\n",
      "2004/2004 [==============================] - 183s 91ms/step - loss: 3.0646 - acc: 0.2541 - val_loss: 2.9519 - val_acc: 0.2868\n",
      "Epoch 6/20\n",
      "2004/2004 [==============================] - 183s 91ms/step - loss: 3.0350 - acc: 0.2546 - val_loss: 2.9959 - val_acc: 0.2865\n",
      "Epoch 7/20\n",
      "2004/2004 [==============================] - 183s 91ms/step - loss: 3.1111 - acc: 0.2543 - val_loss: 8.1460 - val_acc: 0.2861\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 187s 91ms/step - loss: 3.0648 - acc: 0.2553 - val_loss: 11.6137 - val_acc: 0.2859\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 186s 90ms/step - loss: 3.0556 - acc: 0.2553 - val_loss: 3.0308 - val_acc: 0.2856\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 187s 91ms/step - loss: 3.1205 - acc: 0.2553 - val_loss: 3.0448 - val_acc: 0.2862\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 187s 91ms/step - loss: 3.0034 - acc: 0.2551 - val_loss: 2.8867 - val_acc: 0.2868\n",
      "Epoch 5/20\n",
      "2062/2062 [==============================] - 190s 92ms/step - loss: 3.0060 - acc: 0.2556 - val_loss: 2.9023 - val_acc: 0.2855\n",
      "Epoch 6/20\n",
      "2062/2062 [==============================] - 188s 91ms/step - loss: 3.0335 - acc: 0.2550 - val_loss: 3.0410 - val_acc: 0.2849\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 746s 349ms/step - loss: 3.0651 - acc: 0.2599 - val_loss: 4.1233 - val_acc: 0.2624\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.0372 - acc: 0.2597 - val_loss: 3.5102 - val_acc: 0.2620\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 2.9711 - acc: 0.2599 - val_loss: 11.0577 - val_acc: 0.2620\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 191s 89ms/step - loss: 3.0136 - acc: 0.2600 - val_loss: 9.0505 - val_acc: 0.2629\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#훈련 6개의 데이터 셋으로 진행(Validation 데이터 셋이 다름)\n",
    "DATASET_NUM = 6\n",
    "EPOCH_NUM = 20\n",
    "BATCH_SIZE = 32\n",
    "CYCLE_NUM = 8\n",
    "\n",
    "#훈련용 이미지 생성기\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "\n",
    "# Weight, Model 저장용 폴더 생성\n",
    "model_save_dir = \"./Models/AlexNet/\" + NOW\n",
    "MakeDirectory(model_save_dir)\n",
    "\n",
    "#모델 저장\n",
    "model_json = model.to_json()\n",
    "with open(model_save_dir + \"/model_alexnet_\" + NOW + \".json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "             \n",
    "#몇 사이클 돌지\n",
    "for cycle in range(0, CYCLE_NUM):\n",
    "    \n",
    "    print(\"Cycle \", (cycle + 1))\n",
    "    \n",
    "    # 데이터셋 수 만큼 훈련\n",
    "    for index in range(1, (DATASET_NUM + 1)):\n",
    "\n",
    "        print(\"Training \", index)\n",
    "\n",
    "        # 데이터 셋 생성\n",
    "        dir_path = \"\".join(['./Dataset_Multi/Dataset', str(index)])\n",
    "        training_set = train_datagen.flow_from_directory(dir_path + '/Train',\n",
    "                                                    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                    batch_size = BATCH_SIZE)\n",
    "\n",
    "        validation_set = validation_datagen.flow_from_directory(dir_path + '/Validation',\n",
    "                                                   target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                   batch_size = BATCH_SIZE)\n",
    "\n",
    "        #배치 수 계산\n",
    "        train_step_epoch = int(len(training_set.classes) / BATCH_SIZE)\n",
    "        validation_step_epoch = int(len(validation_set.classes) / BATCH_SIZE)\n",
    "        \n",
    "        #훈련!\n",
    "        model.fit_generator(training_set,\n",
    "                            steps_per_epoch = train_step_epoch,\n",
    "                            epochs = EPOCH_NUM,\n",
    "                            validation_data = validation_set,\n",
    "                            validation_steps = validation_step_epoch,\n",
    "                            #class_weight=class_weights,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "        print(\"Traing \", index, \" done\")\n",
    "        \n",
    "        #오늘 날짜_시간\n",
    "        current_time = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "        \n",
    "        # Weight 저장\n",
    "        model.save_weights(model_save_dir + \"/weight_alexnet_\" + current_time + \".h5\")\n",
    "        print(\"Saved model to disk\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "acc: 22.72%\n",
      "-- Predict --\n",
      "{'A': 0, 'AB': 1, 'ABC': 2, 'ABCD': 3, 'ABD': 4, 'AC': 5, 'ACD': 6, 'AD': 7, 'B': 8, 'BC': 9, 'BCD': 10, 'BD': 11, 'C': 12, 'CD': 13, 'D': 14, 'N': 15}\n",
      "[0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.075 0.000 0.047 0.000 0.000\n",
      " 0.000 0.002 0.002 0.871]\n"
     ]
    }
   ],
   "source": [
    "#테스트셋 불러오기\n",
    "test_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "test_set = validation_datagen.flow_from_directory('./Dataset/Test',\n",
    "                                           target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                           batch_size = BATCH_SIZE)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(\n",
    "            test_set, \n",
    "            steps = 100)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_set, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_set.class_indices)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가하기 - 트레이닝 셋으로\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(\n",
    "            training_set, \n",
    "            steps = 100)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기 - 트레이닝 셋으로\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(training_set, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(training_set.class_indices)\n",
    "print(output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
