{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.applications.densenet as densenet\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "#이미지 생성용\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter\n",
    "\n",
    "# 콜백 함수\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#시간 구하기용\n",
    "from datetime import datetime\n",
    "\n",
    "#디렉토리 생성용\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 64, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 16)           16400       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,053,904\n",
      "Trainable params: 6,970,256\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 설정값들\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_DEPTH = 3\n",
    "LABEL_NUM = 16\n",
    "\n",
    "# 이미지 volume 값\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_DEPTH)\n",
    "\n",
    "#GetCNN Model\n",
    "model = densenet.DenseNet121(include_top=True, weights=None, input_shape=input_shape, pooling='max', classes=LABEL_NUM)\n",
    "\n",
    "# 모델 출력\n",
    "model.summary()\n",
    "\n",
    "#Compling CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation값에 따라 훈련 조기종료 설정\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "\n",
    "# Class Weights 계산\n",
    "# 가장 많은 클레스의 수 / 각 클레스의 수\n",
    "# 클레스 = 각 라벨에 해당하는 데이터 수\n",
    "'''\n",
    "counter = Counter(training_set.classes)\n",
    "max_val = float(max(counter.values()))\n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\n",
    "'''\n",
    "\n",
    "#오늘 날짜_시간\n",
    "NOW = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "#텐서보드 로그\n",
    "tensorboard = TensorBoard(log_dir=\"./Logs/DenseNet/\" + NOW)\n",
    "\n",
    "#디렉토리 생성\n",
    "def MakeDirectory(dir_path):\n",
    "    try:\n",
    "        if not(os.path.isdir(dir_path)):\n",
    "            os.makedirs(os.path.join(dir_path))\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle  1\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 869s 445ms/step - loss: 2.4718 - acc: 0.2569 - val_loss: 2.4800 - val_acc: 0.2538\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 334s 171ms/step - loss: 2.4172 - acc: 0.2622 - val_loss: 2.6046 - val_acc: 0.2537\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 335s 171ms/step - loss: 2.3796 - acc: 0.2676 - val_loss: 2.5501 - val_acc: 0.2410\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 832s 387ms/step - loss: 2.3499 - acc: 0.2715 - val_loss: 2.5118 - val_acc: 0.2491\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 168ms/step - loss: 2.3147 - acc: 0.2739 - val_loss: 2.3925 - val_acc: 0.2501\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 2.2879 - acc: 0.2787 - val_loss: 2.4267 - val_acc: 0.2508\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 2.2532 - acc: 0.2845 - val_loss: 2.4710 - val_acc: 0.2467\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 812s 417ms/step - loss: 2.2293 - acc: 0.2921 - val_loss: 2.5365 - val_acc: 0.1858\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 336s 173ms/step - loss: 2.1854 - acc: 0.3030 - val_loss: 2.4350 - val_acc: 0.2260\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 2.1516 - acc: 0.3080 - val_loss: 2.4315 - val_acc: 0.2312\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 2.1105 - acc: 0.3188 - val_loss: 2.4932 - val_acc: 0.2368\n",
      "Epoch 5/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 2.0692 - acc: 0.3290 - val_loss: 2.5285 - val_acc: 0.2328\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 824s 411ms/step - loss: 2.0952 - acc: 0.3169 - val_loss: 2.1983 - val_acc: 0.2988\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 343s 171ms/step - loss: 2.0394 - acc: 0.3298 - val_loss: 2.2470 - val_acc: 0.2722\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 1.9862 - acc: 0.3442 - val_loss: 2.4483 - val_acc: 0.2716\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 808s 392ms/step - loss: 1.9948 - acc: 0.3449 - val_loss: 1.9918 - val_acc: 0.3581\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 351s 170ms/step - loss: 1.9398 - acc: 0.3595 - val_loss: 2.1204 - val_acc: 0.3093\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 1.8793 - acc: 0.3748 - val_loss: 2.1051 - val_acc: 0.3396\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 867s 405ms/step - loss: 1.8702 - acc: 0.3745 - val_loss: 1.7979 - val_acc: 0.4200\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 1.8039 - acc: 0.3925 - val_loss: 2.0966 - val_acc: 0.3678\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 358s 167ms/step - loss: 1.7334 - acc: 0.4158 - val_loss: 1.8618 - val_acc: 0.4050\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  2\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 1.7122 - acc: 0.4273 - val_loss: 1.6806 - val_acc: 0.4307\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 1.6222 - acc: 0.4516 - val_loss: 1.8520 - val_acc: 0.3882\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 1.5279 - acc: 0.4829 - val_loss: 1.7874 - val_acc: 0.4117\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 1.5123 - acc: 0.4843 - val_loss: 1.4666 - val_acc: 0.5016\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 1.4139 - acc: 0.5174 - val_loss: 1.5689 - val_acc: 0.4663\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 359s 167ms/step - loss: 1.3127 - acc: 0.5487 - val_loss: 1.7072 - val_acc: 0.4314\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 1.2619 - acc: 0.5689 - val_loss: 1.3868 - val_acc: 0.5173\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 1.1294 - acc: 0.6135 - val_loss: 1.4542 - val_acc: 0.4996\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 1.0176 - acc: 0.6505 - val_loss: 1.5056 - val_acc: 0.4816\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 1.0702 - acc: 0.6327 - val_loss: 0.8476 - val_acc: 0.7150\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.9513 - acc: 0.6713 - val_loss: 0.9997 - val_acc: 0.6538\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.8596 - acc: 0.7027 - val_loss: 1.1707 - val_acc: 0.6072\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.8701 - acc: 0.7014 - val_loss: 0.7646 - val_acc: 0.7375\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.7600 - acc: 0.7374 - val_loss: 0.8439 - val_acc: 0.7026\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.6794 - acc: 0.7665 - val_loss: 1.0265 - val_acc: 0.6560\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 360s 168ms/step - loss: 0.6942 - acc: 0.7607 - val_loss: 0.5401 - val_acc: 0.8193\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.6095 - acc: 0.7901 - val_loss: 0.6928 - val_acc: 0.7737\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 358s 167ms/step - loss: 0.5546 - acc: 0.8098 - val_loss: 0.8731 - val_acc: 0.7112\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  3\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 337s 172ms/step - loss: 0.5688 - acc: 0.8043 - val_loss: 0.4154 - val_acc: 0.8632\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.4885 - acc: 0.8338 - val_loss: 0.4668 - val_acc: 0.8370\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.4477 - acc: 0.8467 - val_loss: 0.7276 - val_acc: 0.7565\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.4947 - acc: 0.8303 - val_loss: 0.4509 - val_acc: 0.8488\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.4222 - acc: 0.8560 - val_loss: 0.4452 - val_acc: 0.8480\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.3988 - acc: 0.8628 - val_loss: 0.5980 - val_acc: 0.7911\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.3754 - acc: 0.8716 - val_loss: 0.7124 - val_acc: 0.7646\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.3204 - acc: 0.8940 - val_loss: 0.5416 - val_acc: 0.8013\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.2716 - acc: 0.9097 - val_loss: 0.5904 - val_acc: 0.7818\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.2594 - acc: 0.9124 - val_loss: 0.6546 - val_acc: 0.7663\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.3925 - acc: 0.8682 - val_loss: 0.2238 - val_acc: 0.9278\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.3323 - acc: 0.8874 - val_loss: 0.3718 - val_acc: 0.8738\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.3221 - acc: 0.8916 - val_loss: 0.5810 - val_acc: 0.8084\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.3436 - acc: 0.8820 - val_loss: 0.2224 - val_acc: 0.9283\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.3051 - acc: 0.8962 - val_loss: 0.4680 - val_acc: 0.8459\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.2942 - acc: 0.8987 - val_loss: 0.3221 - val_acc: 0.8902\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.3055 - acc: 0.8939 - val_loss: 0.2861 - val_acc: 0.9042\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 361s 169ms/step - loss: 0.2793 - acc: 0.9031 - val_loss: 0.1638 - val_acc: 0.9478\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.2760 - acc: 0.9055 - val_loss: 0.2333 - val_acc: 0.9235\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.2635 - acc: 0.9089 - val_loss: 0.9092 - val_acc: 0.7342\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  4\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 337s 172ms/step - loss: 0.2900 - acc: 0.8985 - val_loss: 0.1532 - val_acc: 0.9522\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.2571 - acc: 0.9078 - val_loss: 0.1792 - val_acc: 0.9433\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.2512 - acc: 0.9141 - val_loss: 0.5395 - val_acc: 0.8285\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.2687 - acc: 0.9062 - val_loss: 0.1671 - val_acc: 0.9457\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.2328 - acc: 0.9174 - val_loss: 0.3529 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.2417 - acc: 0.9145 - val_loss: 0.2302 - val_acc: 0.9219\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.1594 - acc: 0.9483 - val_loss: 0.8837 - val_acc: 0.7153\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.1630 - acc: 0.9466 - val_loss: 0.5088 - val_acc: 0.8092\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.1544 - acc: 0.9489 - val_loss: 0.5706 - val_acc: 0.7973\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.1438 - acc: 0.9527 - val_loss: 0.5379 - val_acc: 0.8025\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.2688 - acc: 0.9071 - val_loss: 0.1893 - val_acc: 0.9377\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.2264 - acc: 0.9208 - val_loss: 0.1865 - val_acc: 0.9381\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.2261 - acc: 0.9213 - val_loss: 0.1903 - val_acc: 0.9368\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.2141 - acc: 0.9242 - val_loss: 0.3016 - val_acc: 0.8989\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 351s 170ms/step - loss: 0.2380 - acc: 0.9157 - val_loss: 0.0979 - val_acc: 0.9688\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 352s 171ms/step - loss: 0.2112 - acc: 0.9240 - val_loss: 0.4412 - val_acc: 0.8573\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 352s 171ms/step - loss: 0.2077 - acc: 0.9262 - val_loss: 0.4314 - val_acc: 0.8634\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.2091 - acc: 0.9252 - val_loss: 0.0825 - val_acc: 0.9765\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.2041 - acc: 0.9266 - val_loss: 0.1608 - val_acc: 0.9475\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1923 - acc: 0.9300 - val_loss: 0.1933 - val_acc: 0.9334\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  5\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 337s 172ms/step - loss: 0.2076 - acc: 0.9239 - val_loss: 0.1988 - val_acc: 0.9345\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1932 - acc: 0.9278 - val_loss: 0.1650 - val_acc: 0.9462\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1963 - acc: 0.9271 - val_loss: 0.1634 - val_acc: 0.9460\n",
      "Epoch 4/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1854 - acc: 0.9307 - val_loss: 0.3819 - val_acc: 0.8758\n",
      "Epoch 5/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1875 - acc: 0.9304 - val_loss: 0.2271 - val_acc: 0.9237\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1997 - acc: 0.9262 - val_loss: 0.0916 - val_acc: 0.9713\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1850 - acc: 0.9318 - val_loss: 0.1655 - val_acc: 0.9420\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1768 - acc: 0.9349 - val_loss: 0.2265 - val_acc: 0.9268\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.1155 - acc: 0.9626 - val_loss: 0.3102 - val_acc: 0.8671\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.1053 - acc: 0.9653 - val_loss: 0.3804 - val_acc: 0.8481\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 336s 173ms/step - loss: 0.1071 - acc: 0.9647 - val_loss: 0.3688 - val_acc: 0.8525\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.2026 - acc: 0.9261 - val_loss: 0.2159 - val_acc: 0.9294\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1726 - acc: 0.9356 - val_loss: 0.1867 - val_acc: 0.9364\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1743 - acc: 0.9346 - val_loss: 0.3428 - val_acc: 0.8875\n",
      "Epoch 4/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1734 - acc: 0.9350 - val_loss: 0.2791 - val_acc: 0.9103\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1850 - acc: 0.9305 - val_loss: 0.1917 - val_acc: 0.9358\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1698 - acc: 0.9359 - val_loss: 0.1147 - val_acc: 0.9623\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1667 - acc: 0.9367 - val_loss: 0.3068 - val_acc: 0.9014\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1641 - acc: 0.9377 - val_loss: 0.2278 - val_acc: 0.9216\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1679 - acc: 0.9359 - val_loss: 0.0917 - val_acc: 0.9704\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.1572 - acc: 0.9401 - val_loss: 0.1444 - val_acc: 0.9520\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1627 - acc: 0.9377 - val_loss: 0.1196 - val_acc: 0.9621\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  6\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1687 - acc: 0.9341 - val_loss: 0.0663 - val_acc: 0.9796\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1566 - acc: 0.9380 - val_loss: 0.0993 - val_acc: 0.9679\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1586 - acc: 0.9381 - val_loss: 0.1064 - val_acc: 0.9641\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1628 - acc: 0.9366 - val_loss: 0.0756 - val_acc: 0.9760\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1509 - acc: 0.9412 - val_loss: 0.1465 - val_acc: 0.9518\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1517 - acc: 0.9416 - val_loss: 0.0797 - val_acc: 0.9733\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0884 - acc: 0.9711 - val_loss: 0.4465 - val_acc: 0.8292\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0834 - acc: 0.9730 - val_loss: 0.3351 - val_acc: 0.8584\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0875 - acc: 0.9715 - val_loss: 0.3434 - val_acc: 0.8565\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0790 - acc: 0.9736 - val_loss: 0.2979 - val_acc: 0.8694\n",
      "Epoch 5/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0792 - acc: 0.9742 - val_loss: 0.4593 - val_acc: 0.8228\n",
      "Epoch 6/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0793 - acc: 0.9735 - val_loss: 0.7761 - val_acc: 0.7546\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 343s 171ms/step - loss: 0.1773 - acc: 0.9357 - val_loss: 0.0846 - val_acc: 0.9719\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1536 - acc: 0.9409 - val_loss: 0.2319 - val_acc: 0.9263\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1496 - acc: 0.9424 - val_loss: 0.1410 - val_acc: 0.9560\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1552 - acc: 0.9399 - val_loss: 0.0448 - val_acc: 0.9861\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1463 - acc: 0.9432 - val_loss: 0.0522 - val_acc: 0.9829\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1484 - acc: 0.9417 - val_loss: 0.0755 - val_acc: 0.9755\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1425 - acc: 0.9437 - val_loss: 0.0921 - val_acc: 0.9702\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.1386 - acc: 0.9452 - val_loss: 0.1089 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 358s 167ms/step - loss: 0.1388 - acc: 0.9441 - val_loss: 0.0553 - val_acc: 0.9825\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.1418 - acc: 0.9440 - val_loss: 0.1577 - val_acc: 0.9485\n",
      "Epoch 5/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.1383 - acc: 0.9456 - val_loss: 0.1202 - val_acc: 0.9616\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  7\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 337s 172ms/step - loss: 0.1455 - acc: 0.9410 - val_loss: 0.1633 - val_acc: 0.9475\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1393 - acc: 0.9426 - val_loss: 0.1351 - val_acc: 0.9559\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 337s 172ms/step - loss: 0.1424 - acc: 0.9421 - val_loss: 0.0864 - val_acc: 0.9722\n",
      "Epoch 4/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1336 - acc: 0.9438 - val_loss: 0.1862 - val_acc: 0.9403\n",
      "Epoch 5/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1358 - acc: 0.9441 - val_loss: 0.1118 - val_acc: 0.9638\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 168ms/step - loss: 0.1398 - acc: 0.9441 - val_loss: 0.0437 - val_acc: 0.9859\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1323 - acc: 0.9450 - val_loss: 0.0707 - val_acc: 0.9770\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1256 - acc: 0.9483 - val_loss: 0.1325 - val_acc: 0.9566\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.0692 - acc: 0.9781 - val_loss: 0.4138 - val_acc: 0.8353\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.0620 - acc: 0.9797 - val_loss: 0.2639 - val_acc: 0.8778\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.0693 - acc: 0.9771 - val_loss: 0.2900 - val_acc: 0.8705\n",
      "Epoch 4/20\n",
      "1946/1946 [==============================] - 335s 172ms/step - loss: 0.0659 - acc: 0.9780 - val_loss: 0.2871 - val_acc: 0.8722\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1468 - acc: 0.9426 - val_loss: 0.0626 - val_acc: 0.9794\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1308 - acc: 0.9466 - val_loss: 0.0686 - val_acc: 0.9779\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1330 - acc: 0.9454 - val_loss: 0.1135 - val_acc: 0.9619\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1339 - acc: 0.9459 - val_loss: 0.0475 - val_acc: 0.9842\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1306 - acc: 0.9464 - val_loss: 0.0500 - val_acc: 0.9802\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1228 - acc: 0.9487 - val_loss: 0.0586 - val_acc: 0.9814\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1268 - acc: 0.9479 - val_loss: 0.0682 - val_acc: 0.9795\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1239 - acc: 0.9495 - val_loss: 0.0495 - val_acc: 0.9842\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1168 - acc: 0.9510 - val_loss: 0.0526 - val_acc: 0.9834\n",
      "Epoch 4/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1205 - acc: 0.9494 - val_loss: 0.1169 - val_acc: 0.9622\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n",
      "Cycle  8\n",
      "Training  1\n",
      "Found 62573 images belonging to 16 classes.\n",
      "Found 15875 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1339 - acc: 0.9431 - val_loss: 0.0777 - val_acc: 0.9729\n",
      "Epoch 2/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1228 - acc: 0.9474 - val_loss: 0.0575 - val_acc: 0.9819\n",
      "Epoch 3/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1208 - acc: 0.9478 - val_loss: 0.0438 - val_acc: 0.9866\n",
      "Epoch 4/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1242 - acc: 0.9464 - val_loss: 0.1047 - val_acc: 0.9648\n",
      "Epoch 5/20\n",
      "1955/1955 [==============================] - 336s 172ms/step - loss: 0.1199 - acc: 0.9486 - val_loss: 0.1219 - val_acc: 0.9590\n",
      "Traing  1  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  2\n",
      "Found 68806 images belonging to 16 classes.\n",
      "Found 9642 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1275 - acc: 0.9469 - val_loss: 0.0408 - val_acc: 0.9856\n",
      "Epoch 2/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1172 - acc: 0.9495 - val_loss: 0.0280 - val_acc: 0.9920\n",
      "Epoch 3/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1157 - acc: 0.9500 - val_loss: 0.1114 - val_acc: 0.9641\n",
      "Epoch 4/20\n",
      "2150/2150 [==============================] - 360s 167ms/step - loss: 0.1133 - acc: 0.9512 - val_loss: 0.0478 - val_acc: 0.9851\n",
      "Traing  2  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  3\n",
      "Found 62272 images belonging to 16 classes.\n",
      "Found 16176 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0609 - acc: 0.9804 - val_loss: 0.2369 - val_acc: 0.8810\n",
      "Epoch 2/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0585 - acc: 0.9803 - val_loss: 0.2597 - val_acc: 0.8764\n",
      "Epoch 3/20\n",
      "1946/1946 [==============================] - 336s 172ms/step - loss: 0.0523 - acc: 0.9833 - val_loss: 0.2563 - val_acc: 0.8767\n",
      "Traing  3  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  4\n",
      "Found 64149 images belonging to 16 classes.\n",
      "Found 14299 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1316 - acc: 0.9459 - val_loss: 0.0400 - val_acc: 0.9865\n",
      "Epoch 2/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1204 - acc: 0.9488 - val_loss: 0.0568 - val_acc: 0.9809\n",
      "Epoch 3/20\n",
      "2004/2004 [==============================] - 342s 171ms/step - loss: 0.1171 - acc: 0.9498 - val_loss: 0.0414 - val_acc: 0.9877\n",
      "Traing  4  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  5\n",
      "Found 65987 images belonging to 16 classes.\n",
      "Found 12461 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2062/2062 [==============================] - 350s 170ms/step - loss: 0.1215 - acc: 0.9490 - val_loss: 0.0376 - val_acc: 0.9872\n",
      "Epoch 2/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1155 - acc: 0.9497 - val_loss: 0.0698 - val_acc: 0.9763\n",
      "Epoch 3/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1148 - acc: 0.9503 - val_loss: 0.0373 - val_acc: 0.9884\n",
      "Epoch 4/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1161 - acc: 0.9498 - val_loss: 0.0789 - val_acc: 0.9720\n",
      "Epoch 5/20\n",
      "2062/2062 [==============================] - 349s 169ms/step - loss: 0.1138 - acc: 0.9508 - val_loss: 0.0804 - val_acc: 0.9740\n",
      "Traing  5  done\n",
      "Saved model to disk\n",
      "\n",
      "Training  6\n",
      "Found 68453 images belonging to 16 classes.\n",
      "Found 9995 images belonging to 16 classes.\n",
      "Epoch 1/20\n",
      "2139/2139 [==============================] - 359s 168ms/step - loss: 0.1165 - acc: 0.9496 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 2/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.1079 - acc: 0.9523 - val_loss: 0.0453 - val_acc: 0.9862\n",
      "Epoch 3/20\n",
      "2139/2139 [==============================] - 358s 168ms/step - loss: 0.1100 - acc: 0.9523 - val_loss: 0.0447 - val_acc: 0.9844\n",
      "Traing  6  done\n",
      "Saved model to disk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#훈련 6개의 데이터 셋으로 진행(Validation 데이터 셋이 다름)\n",
    "DATASET_NUM = 6\n",
    "EPOCH_NUM = 20\n",
    "BATCH_SIZE = 32\n",
    "CYCLE_NUM = 8\n",
    "\n",
    "#훈련용 이미지 생성기\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "\n",
    "# Weight, Model 저장용 폴더 생성\n",
    "model_save_dir = \"./Models/DenseNet/\" + NOW\n",
    "MakeDirectory(model_save_dir)\n",
    "\n",
    "#모델 저장\n",
    "model_json = model.to_json()\n",
    "with open(model_save_dir + \"/model_densenet_\" + NOW + \".json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "             \n",
    "#몇 사이클 돌지\n",
    "for cycle in range(0, CYCLE_NUM):\n",
    "    \n",
    "    print(\"Cycle \", (cycle + 1))\n",
    "    \n",
    "    # 데이터셋 수 만큼 훈련\n",
    "    for index in range(1, (DATASET_NUM + 1)):\n",
    "\n",
    "        print(\"Training \", index)\n",
    "\n",
    "        # 데이터 셋 생성\n",
    "        dir_path = \"\".join(['./Dataset_Multi/Dataset', str(index)])\n",
    "        training_set = train_datagen.flow_from_directory(dir_path + '/Train',\n",
    "                                                    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                    batch_size = BATCH_SIZE)\n",
    "\n",
    "        validation_set = validation_datagen.flow_from_directory(dir_path + '/Validation',\n",
    "                                                   target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                   batch_size = BATCH_SIZE)\n",
    "\n",
    "        #배치 수 계산\n",
    "        train_step_epoch = int(len(training_set.classes) / BATCH_SIZE)\n",
    "        validation_step_epoch = int(len(validation_set.classes) / BATCH_SIZE)\n",
    "        \n",
    "        #훈련!\n",
    "        model.fit_generator(training_set,\n",
    "                            steps_per_epoch = train_step_epoch,\n",
    "                            epochs = EPOCH_NUM,\n",
    "                            validation_data = validation_set,\n",
    "                            validation_steps = validation_step_epoch,\n",
    "                            #class_weight=class_weights,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "        print(\"Traing \", index, \" done\")\n",
    "        \n",
    "        #오늘 날짜_시간\n",
    "        current_time = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "        \n",
    "        # Weight 저장\n",
    "        model.save_weights(model_save_dir + \"/weight_densenet_\" + current_time + \".h5\")\n",
    "        print(\"Saved model to disk\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9588 images belonging to 16 classes.\n",
      "-- Evaluate --\n",
      "acc: 19.47%\n",
      "-- Predict --\n",
      "{'A': 0, 'AB': 1, 'ABC': 2, 'ABCD': 3, 'ABD': 4, 'AC': 5, 'ACD': 6, 'AD': 7, 'B': 8, 'BC': 9, 'BCD': 10, 'BD': 11, 'C': 12, 'CD': 13, 'D': 14, 'N': 15}\n",
      "[0.051 0.054 0.000 0.001 0.000 0.000 0.000 0.863 0.002 0.000 0.000 0.001\n",
      " 0.012 0.000 0.015 0.000]\n"
     ]
    }
   ],
   "source": [
    "#테스트셋 불러오기\n",
    "test_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "test_set = validation_datagen.flow_from_directory('./Dataset_Multi/Testset',\n",
    "                                           target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                           batch_size = BATCH_SIZE)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(\n",
    "            test_set, \n",
    "            steps = 100)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_set, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_set.class_indices)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "acc: 94.81%\n",
      "-- Predict --\n",
      "{'A': 0, 'AB': 1, 'ABC': 2, 'ABCD': 3, 'ABD': 4, 'AC': 5, 'ACD': 6, 'AD': 7, 'B': 8, 'BC': 9, 'BCD': 10, 'BD': 11, 'C': 12, 'CD': 13, 'D': 14, 'N': 15}\n",
      "[0.006 0.003 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
      " 0.001 0.002 0.000 0.988]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기 - 트레이닝 셋으로\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(\n",
    "            training_set, \n",
    "            steps = 100)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기 - 트레이닝 셋으로\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(training_set, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(training_set.class_indices)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
