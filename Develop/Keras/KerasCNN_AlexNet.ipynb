{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 임포트\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "#이미지 생성용\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter\n",
    "\n",
    "# 콜백 함수\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#시간 구하기용\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelDesign(size_x, size_y, depth, label_num, regularizer_value):     \n",
    "    #초기화\n",
    "    model = Sequential() \n",
    "    \n",
    "    # CNN 레이어\n",
    "    # 레이어1(Input)\n",
    "    model.add(Conv2D(filters=96,\n",
    "                     input_shape=(size_x,size_y,depth),\n",
    "                     kernel_size=(11,11),\n",
    "                     strides=(4,4),\n",
    "                     padding='valid',\n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    # Activation\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling \n",
    "    model.add(MaxPooling2D((2,2), strides=(1,1), padding='valid'))\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어2\n",
    "    model.add(Conv2D(filters=256, kernel_size=(11,11), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D((2,2), strides=(1,1), padding='valid'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어3\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어4\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 레이어5\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), \n",
    "                     strides=(1,1), padding='valid', \n",
    "                     kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # Dense 레이어\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 레이어1(Input2)\n",
    "    model.add(Dense(4096, input_shape=(size_x*size_y*depth,), \n",
    "                    kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 레이어2\n",
    "    model.add(Dense(4096, kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 레이어3\n",
    "    model.add(Dense(1000, kernel_regularizer=regularizers.l2(regularizer_value)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # 출력 레이어\n",
    "    model.add(Dense(label_num))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #모델 확인\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 29, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 29, 29, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 19, 19, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 19, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                16016     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 64,795,928\n",
      "Trainable params: 64,774,792\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 설정값들\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_DEPTH = 3\n",
    "LABEL_NUM = 16\n",
    "REGULIZER = 0.0001\n",
    "\n",
    "#GetCNN Model\n",
    "model = ModelDesign(IMAGE_SIZE, IMAGE_SIZE, IMAGE_DEPTH, LABEL_NUM, REGULIZER)\n",
    "\n",
    "#Compling CNN\n",
    "#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69267 images belonging to 16 classes.\n",
      "Found 9588 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#배치 크기\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#훈련용 이미지 생성\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./Dataset/Train',\n",
    "                                                target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                batch_size = BATCH_SIZE)\n",
    "\n",
    "validation_set = validation_datagen.flow_from_directory('./Dataset/Validation',\n",
    "                                           target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                           batch_size = BATCH_SIZE)\n",
    "\n",
    "# Val값에 따라 훈련 조기종료 설정\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "# Class Weights 계산\n",
    "# 가장 많은 클레스의 수 / 각 클레스의 수\n",
    "# 클레스 = 각 라벨에 해당하는 데이터 수\n",
    "counter = Counter(training_set.classes)\n",
    "max_val = float(max(counter.values()))\n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\n",
    "\n",
    "#배치 수 계산\n",
    "train_step_epoch = int(len(training_set.classes) / BATCH_SIZE)\n",
    "validation_step_epoch = int(len(validation_set.classes) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4329/4329 [==============================] - 1054s 243ms/step - loss: 3.8040 - acc: 0.2080 - val_loss: 3.6037 - val_acc: 0.2356\n",
      "Epoch 2/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 3.5113 - acc: 0.2409 - val_loss: 3.5635 - val_acc: 0.2353\n",
      "Epoch 3/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 3.3797 - acc: 0.2575 - val_loss: 3.3805 - val_acc: 0.2351\n",
      "Epoch 4/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 3.1970 - acc: 0.2627 - val_loss: 3.1672 - val_acc: 0.2362\n",
      "Epoch 5/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 3.0004 - acc: 0.2623 - val_loss: 3.1488 - val_acc: 0.2355\n",
      "Epoch 6/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.9581 - acc: 0.2626 - val_loss: 3.1164 - val_acc: 0.2355\n",
      "Epoch 7/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.9624 - acc: 0.2625 - val_loss: 3.1021 - val_acc: 0.2350\n",
      "Epoch 8/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.9463 - acc: 0.2625 - val_loss: 3.0106 - val_acc: 0.2362\n",
      "Epoch 9/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.9567 - acc: 0.2626 - val_loss: 6.3399 - val_acc: 0.2353\n",
      "Epoch 10/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.9792 - acc: 0.2628 - val_loss: 3.3082 - val_acc: 0.2357\n",
      "Epoch 11/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.9530 - acc: 0.2622 - val_loss: 3.1220 - val_acc: 0.2350\n",
      "Epoch 12/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.8921 - acc: 0.2624 - val_loss: 6.0571 - val_acc: 0.2358\n",
      "Epoch 13/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.8859 - acc: 0.2625 - val_loss: 3.0008 - val_acc: 0.2350\n",
      "Epoch 14/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.8383 - acc: 0.2626 - val_loss: 2.9267 - val_acc: 0.2363\n",
      "Epoch 15/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.8302 - acc: 0.2626 - val_loss: 2.9387 - val_acc: 0.2346\n",
      "Epoch 16/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.8183 - acc: 0.2625 - val_loss: 3.9561 - val_acc: 0.2363\n",
      "Epoch 17/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.7681 - acc: 0.2626 - val_loss: 2.8679 - val_acc: 0.2358\n",
      "Epoch 18/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.7437 - acc: 0.2626 - val_loss: 2.8459 - val_acc: 0.2345\n",
      "Epoch 19/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.7164 - acc: 0.2626 - val_loss: 2.8190 - val_acc: 0.2359\n",
      "Epoch 20/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.7084 - acc: 0.2625 - val_loss: 4.7287 - val_acc: 0.2351\n",
      "Epoch 21/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.7350 - acc: 0.2626 - val_loss: 3.0233 - val_acc: 0.2360\n",
      "Epoch 22/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6928 - acc: 0.2626 - val_loss: 3.5627 - val_acc: 0.2368\n",
      "Epoch 23/150\n",
      "4329/4329 [==============================] - 347s 80ms/step - loss: 2.6776 - acc: 0.2622 - val_loss: 3.5832 - val_acc: 0.2324\n",
      "Epoch 24/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6790 - acc: 0.2632 - val_loss: 2.8607 - val_acc: 0.2357\n",
      "Epoch 25/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6820 - acc: 0.2630 - val_loss: 3.4864 - val_acc: 0.2188\n",
      "Epoch 26/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6945 - acc: 0.2634 - val_loss: 12.5445 - val_acc: 0.2362\n",
      "Epoch 27/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6553 - acc: 0.2634 - val_loss: 3.6621 - val_acc: 0.2136\n",
      "Epoch 28/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6324 - acc: 0.2641 - val_loss: 3.3534 - val_acc: 0.2131\n",
      "Epoch 29/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6366 - acc: 0.2638 - val_loss: 3.4303 - val_acc: 0.2059\n",
      "Epoch 30/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6274 - acc: 0.2651 - val_loss: 3.3854 - val_acc: 0.2470\n",
      "Epoch 31/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6209 - acc: 0.2641 - val_loss: 3.1466 - val_acc: 0.2204\n",
      "Epoch 32/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6314 - acc: 0.2645 - val_loss: 2.9733 - val_acc: 0.2351\n",
      "Epoch 33/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6439 - acc: 0.2644 - val_loss: 3.0848 - val_acc: 0.2396\n",
      "Epoch 34/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6545 - acc: 0.2658 - val_loss: 3.2146 - val_acc: 0.2230\n",
      "Epoch 35/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6429 - acc: 0.2659 - val_loss: 3.0592 - val_acc: 0.2283\n",
      "Epoch 36/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6297 - acc: 0.2645 - val_loss: 3.2539 - val_acc: 0.2149\n",
      "Epoch 37/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6665 - acc: 0.2647 - val_loss: 3.1882 - val_acc: 0.2293\n",
      "Epoch 38/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6494 - acc: 0.2638 - val_loss: 3.8465 - val_acc: 0.1980\n",
      "Epoch 39/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6328 - acc: 0.2652 - val_loss: 3.4182 - val_acc: 0.2268\n",
      "Epoch 40/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6117 - acc: 0.2655 - val_loss: 3.2748 - val_acc: 0.2179\n",
      "Epoch 41/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6007 - acc: 0.2654 - val_loss: 2.9697 - val_acc: 0.2367\n",
      "Epoch 42/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6243 - acc: 0.2626 - val_loss: 3.1446 - val_acc: 0.2354\n",
      "Epoch 43/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6148 - acc: 0.2625 - val_loss: 3.0797 - val_acc: 0.2241\n",
      "Epoch 44/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5931 - acc: 0.2644 - val_loss: 2.9788 - val_acc: 0.2203\n",
      "Epoch 45/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6146 - acc: 0.2635 - val_loss: 3.9707 - val_acc: 0.1876\n",
      "Epoch 46/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6377 - acc: 0.2642 - val_loss: 3.3022 - val_acc: 0.2375\n",
      "Epoch 47/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6244 - acc: 0.2628 - val_loss: 15.7190 - val_acc: 0.0344\n",
      "Epoch 48/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6375 - acc: 0.2641 - val_loss: 3.1971 - val_acc: 0.2285\n",
      "Epoch 49/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6139 - acc: 0.2650 - val_loss: 10.1534 - val_acc: 0.0957\n",
      "Epoch 50/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6129 - acc: 0.2642 - val_loss: 4.5669 - val_acc: 0.2178\n",
      "Epoch 51/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6039 - acc: 0.2634 - val_loss: 3.8603 - val_acc: 0.2009\n",
      "Epoch 52/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6163 - acc: 0.2642 - val_loss: 3.7260 - val_acc: 0.1984\n",
      "Epoch 53/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6159 - acc: 0.2645 - val_loss: 3.3730 - val_acc: 0.2065\n",
      "Epoch 54/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6147 - acc: 0.2652 - val_loss: 3.5924 - val_acc: 0.2002\n",
      "Epoch 55/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5985 - acc: 0.2639 - val_loss: 3.0770 - val_acc: 0.2198\n",
      "Epoch 56/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6179 - acc: 0.2649 - val_loss: 3.0248 - val_acc: 0.2367\n",
      "Epoch 57/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6367 - acc: 0.2657 - val_loss: 2.9400 - val_acc: 0.2245\n",
      "Epoch 58/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6139 - acc: 0.2645 - val_loss: 2.9632 - val_acc: 0.2396\n",
      "Epoch 59/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6130 - acc: 0.2646 - val_loss: 3.0570 - val_acc: 0.2229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6088 - acc: 0.2655 - val_loss: 2.8651 - val_acc: 0.2372\n",
      "Epoch 61/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6000 - acc: 0.2658 - val_loss: 3.1900 - val_acc: 0.2093\n",
      "Epoch 62/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6105 - acc: 0.2665 - val_loss: 3.0661 - val_acc: 0.2230\n",
      "Epoch 63/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6253 - acc: 0.2660 - val_loss: 3.2491 - val_acc: 0.2396\n",
      "Epoch 64/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6119 - acc: 0.2655 - val_loss: 3.1170 - val_acc: 0.2288\n",
      "Epoch 65/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6056 - acc: 0.2665 - val_loss: 5.2671 - val_acc: 0.1966\n",
      "Epoch 66/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6081 - acc: 0.2665 - val_loss: 2.8506 - val_acc: 0.2368\n",
      "Epoch 67/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6094 - acc: 0.2649 - val_loss: 3.3653 - val_acc: 0.2216\n",
      "Epoch 68/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6045 - acc: 0.2655 - val_loss: 3.2895 - val_acc: 0.2228\n",
      "Epoch 69/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6235 - acc: 0.2655 - val_loss: 2.9030 - val_acc: 0.2266\n",
      "Epoch 70/150\n",
      "4329/4329 [==============================] - 347s 80ms/step - loss: 2.5912 - acc: 0.2661 - val_loss: 15.3032 - val_acc: 0.0618\n",
      "Epoch 71/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5786 - acc: 0.2659 - val_loss: 3.5429 - val_acc: 0.2180\n",
      "Epoch 72/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5854 - acc: 0.2653 - val_loss: 8.9418 - val_acc: 0.1281\n",
      "Epoch 73/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6006 - acc: 0.2638 - val_loss: 5.1907 - val_acc: 0.1649\n",
      "Epoch 74/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6157 - acc: 0.2642 - val_loss: 3.4778 - val_acc: 0.2050\n",
      "Epoch 75/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6281 - acc: 0.2648 - val_loss: 3.0250 - val_acc: 0.2261\n",
      "Epoch 76/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6214 - acc: 0.2640 - val_loss: 2.9944 - val_acc: 0.2000\n",
      "Epoch 77/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6134 - acc: 0.2638 - val_loss: 2.8766 - val_acc: 0.2281\n",
      "Epoch 78/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5905 - acc: 0.2653 - val_loss: 8.9143 - val_acc: 0.1146\n",
      "Epoch 79/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5946 - acc: 0.2631 - val_loss: 3.0890 - val_acc: 0.2039\n",
      "Epoch 80/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5688 - acc: 0.2657 - val_loss: 15.3642 - val_acc: 0.0571\n",
      "Epoch 81/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5788 - acc: 0.2646 - val_loss: 3.2514 - val_acc: 0.2277\n",
      "Epoch 82/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6154 - acc: 0.2646 - val_loss: 15.4883 - val_acc: 0.0509\n",
      "Epoch 83/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6009 - acc: 0.2656 - val_loss: 2.8664 - val_acc: 0.2310\n",
      "Epoch 84/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5786 - acc: 0.2644 - val_loss: 3.0175 - val_acc: 0.2215\n",
      "Epoch 85/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5796 - acc: 0.2655 - val_loss: 3.2829 - val_acc: 0.1905\n",
      "Epoch 86/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5688 - acc: 0.2648 - val_loss: 3.7420 - val_acc: 0.2364\n",
      "Epoch 87/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5598 - acc: 0.2653 - val_loss: 2.8675 - val_acc: 0.2352\n",
      "Epoch 88/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5648 - acc: 0.2657 - val_loss: 3.1927 - val_acc: 0.2357\n",
      "Epoch 89/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.6090 - acc: 0.2649 - val_loss: 2.9287 - val_acc: 0.2248\n",
      "Epoch 90/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5884 - acc: 0.2645 - val_loss: 2.8122 - val_acc: 0.2375\n",
      "Epoch 91/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5832 - acc: 0.2649 - val_loss: 3.3110 - val_acc: 0.2356\n",
      "Epoch 92/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5623 - acc: 0.2640 - val_loss: 14.5455 - val_acc: 0.0341\n",
      "Epoch 93/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5686 - acc: 0.2649 - val_loss: 3.1318 - val_acc: 0.2063\n",
      "Epoch 94/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5850 - acc: 0.2647 - val_loss: 3.9696 - val_acc: 0.2051\n",
      "Epoch 95/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5820 - acc: 0.2645 - val_loss: 3.0014 - val_acc: 0.2240\n",
      "Epoch 96/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5723 - acc: 0.2650 - val_loss: 14.6372 - val_acc: 0.0285\n",
      "Epoch 97/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5594 - acc: 0.2661 - val_loss: 14.2571 - val_acc: 0.0333\n",
      "Epoch 98/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5573 - acc: 0.2660 - val_loss: 4.7273 - val_acc: 0.2346\n",
      "Epoch 99/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5694 - acc: 0.2663 - val_loss: 3.9310 - val_acc: 0.1792\n",
      "Epoch 100/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5855 - acc: 0.2625 - val_loss: 3.1108 - val_acc: 0.2261\n",
      "Epoch 101/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5700 - acc: 0.2657 - val_loss: 15.8635 - val_acc: 0.0250\n",
      "Epoch 102/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5678 - acc: 0.2652 - val_loss: 15.8692 - val_acc: 0.0234\n",
      "Epoch 103/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5866 - acc: 0.2627 - val_loss: 15.3592 - val_acc: 0.0551\n",
      "Epoch 104/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5683 - acc: 0.2646 - val_loss: 12.0233 - val_acc: 0.1207\n",
      "Epoch 105/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5661 - acc: 0.2648 - val_loss: 2.9268 - val_acc: 0.2262\n",
      "Epoch 106/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5623 - acc: 0.2651 - val_loss: 3.4289 - val_acc: 0.2090\n",
      "Epoch 107/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5719 - acc: 0.2646 - val_loss: 15.8217 - val_acc: 0.0234\n",
      "Epoch 108/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5441 - acc: 0.2645 - val_loss: 12.7164 - val_acc: 0.0635\n",
      "Epoch 109/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5696 - acc: 0.2658 - val_loss: 14.7272 - val_acc: 0.0493\n",
      "Epoch 110/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5778 - acc: 0.2653 - val_loss: 12.6178 - val_acc: 0.0506\n",
      "Epoch 111/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5587 - acc: 0.2657 - val_loss: 2.7893 - val_acc: 0.2360\n",
      "Epoch 112/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5698 - acc: 0.2654 - val_loss: 3.3686 - val_acc: 0.2194\n",
      "Epoch 113/150\n",
      "4329/4329 [==============================] - 346s 80ms/step - loss: 2.5687 - acc: 0.2662 - val_loss: 2.8331 - val_acc: 0.2337\n",
      "Epoch 114/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5566 - acc: 0.2662 - val_loss: 2.9934 - val_acc: 0.2221\n",
      "Epoch 115/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5577 - acc: 0.2657 - val_loss: 3.3290 - val_acc: 0.2256\n",
      "Epoch 116/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5572 - acc: 0.2642 - val_loss: 12.5034 - val_acc: 0.2378\n",
      "Epoch 117/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.6386 - acc: 0.2630 - val_loss: 10.6488 - val_acc: 0.0963\n",
      "Epoch 118/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5818 - acc: 0.2634 - val_loss: 15.8553 - val_acc: 0.0242\n",
      "Epoch 119/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5560 - acc: 0.2618 - val_loss: 10.0307 - val_acc: 0.2372\n",
      "Epoch 120/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5448 - acc: 0.2649 - val_loss: 5.3108 - val_acc: 0.2315\n",
      "Epoch 121/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5643 - acc: 0.2620 - val_loss: 2.7067 - val_acc: 0.2345\n",
      "Epoch 122/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5597 - acc: 0.2625 - val_loss: 3.0042 - val_acc: 0.2295\n",
      "Epoch 123/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5425 - acc: 0.2621 - val_loss: 3.1200 - val_acc: 0.2300\n",
      "Epoch 124/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5685 - acc: 0.2626 - val_loss: 2.7489 - val_acc: 0.2323\n",
      "Epoch 125/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5924 - acc: 0.2625 - val_loss: 2.9445 - val_acc: 0.2327\n",
      "Epoch 126/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5893 - acc: 0.2619 - val_loss: 3.0454 - val_acc: 0.2366\n",
      "Epoch 127/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5634 - acc: 0.2626 - val_loss: 2.9536 - val_acc: 0.2219\n",
      "Epoch 128/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5459 - acc: 0.2619 - val_loss: 2.8419 - val_acc: 0.2309\n",
      "Epoch 129/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5623 - acc: 0.2630 - val_loss: 13.5123 - val_acc: 0.0861\n",
      "Epoch 130/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5762 - acc: 0.2621 - val_loss: 15.4316 - val_acc: 0.0516\n",
      "Epoch 131/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5778 - acc: 0.2623 - val_loss: 2.7312 - val_acc: 0.2384\n",
      "Epoch 132/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5768 - acc: 0.2626 - val_loss: 3.0555 - val_acc: 0.2314\n",
      "Epoch 133/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5591 - acc: 0.2627 - val_loss: 14.8865 - val_acc: 0.0775\n",
      "Epoch 134/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5743 - acc: 0.2626 - val_loss: 9.2813 - val_acc: 0.1350\n",
      "Epoch 135/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5639 - acc: 0.2623 - val_loss: 2.9893 - val_acc: 0.2221\n",
      "Epoch 136/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5480 - acc: 0.2621 - val_loss: 14.0651 - val_acc: 0.0424\n",
      "Epoch 137/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5730 - acc: 0.2623 - val_loss: 4.8591 - val_acc: 0.1792\n",
      "Epoch 138/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5649 - acc: 0.2630 - val_loss: 2.8776 - val_acc: 0.2244\n",
      "Epoch 139/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5522 - acc: 0.2634 - val_loss: 2.8650 - val_acc: 0.2313\n",
      "Epoch 140/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5670 - acc: 0.2618 - val_loss: 12.2313 - val_acc: 0.1816\n",
      "Epoch 141/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5949 - acc: 0.2628 - val_loss: 4.3233 - val_acc: 0.1807\n",
      "Epoch 142/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5611 - acc: 0.2632 - val_loss: 2.8848 - val_acc: 0.2324\n",
      "Epoch 143/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5613 - acc: 0.2624 - val_loss: 11.1997 - val_acc: 0.2356\n",
      "Epoch 144/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5557 - acc: 0.2630 - val_loss: 11.9375 - val_acc: 0.2367\n",
      "Epoch 145/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5445 - acc: 0.2623 - val_loss: 15.8441 - val_acc: 0.0230\n",
      "Epoch 146/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5536 - acc: 0.2625 - val_loss: 10.6797 - val_acc: 0.0703\n",
      "Epoch 147/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5355 - acc: 0.2627 - val_loss: 12.5256 - val_acc: 0.2305\n",
      "Epoch 148/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5662 - acc: 0.2630 - val_loss: 4.6654 - val_acc: 0.2354\n",
      "Epoch 149/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5512 - acc: 0.2619 - val_loss: 2.6879 - val_acc: 0.2384\n",
      "Epoch 150/150\n",
      "4329/4329 [==============================] - 345s 80ms/step - loss: 2.5434 - acc: 0.2631 - val_loss: 3.0469 - val_acc: 0.2375\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#오늘 날짜_시간\n",
    "NOW = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "#텐서보드 로그\n",
    "tensorboard = TensorBoard(log_dir=\"./Logs/AlexNet/\" + NOW)\n",
    "\n",
    "#훈련!\n",
    "model.fit_generator(training_set,\n",
    "                    steps_per_epoch = train_step_epoch,\n",
    "                    epochs = 150,\n",
    "                    validation_data = validation_set,\n",
    "                    validation_steps = validation_step_epoch,\n",
    "                    #class_weight=class_weights,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "#모델 저장\n",
    "model_json = model.to_json()\n",
    "with open(\"./Models/AlexNet/model_alex_\" + NOW + \".json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Weight 저장\n",
    "model.save_weights(\"./Models/AlexNet/model_alex_weight_\" + NOW + \".h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "acc: 22.72%\n",
      "-- Predict --\n",
      "{'A': 0, 'AB': 1, 'ABC': 2, 'ABCD': 3, 'ABD': 4, 'AC': 5, 'ACD': 6, 'AD': 7, 'B': 8, 'BC': 9, 'BCD': 10, 'BD': 11, 'C': 12, 'CD': 13, 'D': 14, 'N': 15}\n",
      "[0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.075 0.000 0.047 0.000 0.000\n",
      " 0.000 0.002 0.002 0.871]\n"
     ]
    }
   ],
   "source": [
    "#테스트셋 불러오기\n",
    "test_datagen = ImageDataGenerator(horizontal_flip = True)\n",
    "test_set = validation_datagen.flow_from_directory('./Dataset/Test',\n",
    "                                           target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                           batch_size = BATCH_SIZE)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(\n",
    "            test_set, \n",
    "            steps = 100)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_set, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_set.class_indices)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가하기 - 트레이닝 셋으로\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(\n",
    "            training_set, \n",
    "            steps = 100)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기 - 트레이닝 셋으로\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(training_set, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(training_set.class_indices)\n",
    "print(output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
